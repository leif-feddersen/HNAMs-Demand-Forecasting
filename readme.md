# HNAM Experiments

This repository contains the experimental code, data structure, and pre-trained model checkpoints used in the paper:

> **Hierarchical Neural Additive Models for Interpretable Demand Forecasts**  
> Under Review

---

## Overview

1. **Purpose**  
   - Demonstrates the use of **Hierarchical Neural Additive Models (HNAMs)** for interpretable demand forecasting on two real-world datasets:
     - [Favorita Grocery Sales Forecasting (Kaggle)](https://www.kaggle.com/competitions/favorita-grocery-sales-forecasting/)
     - [Walmart M5 Forecasting (Kaggle)](https://www.kaggle.com/competitions/m5-forecasting-accuracy/)
   - Includes scripts for data preprocessing, evaluation notebooks for accuracy/interpretability/runtime, and pre-trained HNAM checkpoints.

2. **Repository Structure**  
   - **`Datasets/`**  
     - Place original CSVs from the Kaggle competitions inside `Datasets/Favorita` and `Datasets/Walmart`.  
   - **`Preprocessing/`**  
     - Python scripts for data cleaning, transformation, and serialization.
   - **`Fit_and_Predict/`**  
     - Scripts for training various models (HNAM, TFT, ARIMA, Prophet, etc.).  
     - Includes subfolders with model checkpoints.  
   - **`Evaluation/`**  
     - Jupyter notebooks (`evaluation-*.ipynb`) for analyzing results (accuracy, interpretability, runtime).  
     - `predict_all.py` script to generate forecasts from pre-trained models for complete datasets. 
     - Figures, logs, and saved predictions (`.pkl`) are also stored here.  
   - **`Processed/`**  
     - Intermediate `.pkl` data files from the preprocessing stage.  
   - **`preprocess.sh`**  
     - A single script that preprocesses the data.
   - **`predict.sh`**
     - A single script that predicts the complete datasets.

3. **Conda Environment**  
   - **`env.yml`** describes the environment needed to run all experiments (creates an environment named `hnam`).  
   - This includes the [custom PyTorch Forecasting fork](https://github.com/leif-feddersen/pytorch-forecasting/tree/hnam-mods) with HNAM support.

---

## Getting Started

### 1. Clone the Repository

~~~bash
git clone https://github.com/leif-feddersen/hnam_experiments.git
cd hnam_experiments
~~~

### 2. Create and Activate the Conda Environment

Make sure you have [Conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/) installed. Then:

~~~bash
conda env create -f env.yml
conda activate hnam
~~~

--- 

<br><b>If you wish to do local inference in the complete datasets to obtain
the insample predictions required for the complete interpretability evaluation, continue with 3 and 4.
Other evaluations can be run without steps 3 and 4<br></b><br>

### 3 Place raw data and preprocess (optional)

The preprocessed pickles are available. If you wish to run preprocessing locally:
Obtain the original CSVs from Kaggle for both **Favorita** and **Walmart** competitions. Place them in:

```
hnam_experiments/ 
└── 
  hnam_experiments/
  └── Datasets/
      ├── Favorita/
      │   ├── holidays_events.csv
      │   ├── items.csv
      │   ├── oil.csv
      │   ├── sample_submission.csv
      │   ├── stores.csv
      │   ├── test.csv
      │   ├── train.csv
      │   └── transactions.csv
      └── Walmart/
          ├── calendar.csv
          ├── sales_train_evaluation.csv
          ├── sales_train_validation.csv
          ├── sample_submission.csv
          └── sell_prices.csv
```

Now execute the script 'preprocess.sh' from hnam_experiments folder.
~~~bash
cd hnam_experiments
bash preprocess.sh
~~~

This runs `python pre_walmart.py` and `python pre_favorita.py` to generate processed `.pkl` files under `Processed/`.

### 4. Local inference of complete datasets

Execute script `predict.sh` from hnam_experiments folder.

~~~bash
cd hnam_experiments
bash predict.sh
~~~

This calls `predict_all.py` for each dataset (`Walmart`, `WalmartR`, and `Favorita`) to use the pre-trained HNAM models and produce full forecasts. WalmartR uses the same Walmart data with a reversed hierarchy for comparison.

---

## Results and Evaluation

1. **Evaluation Notebooks**  
   - In `Evaluation/`, you’ll find Jupyter notebooks:
     - `evaluation-1_accuracy.ipynb`
     - `evaluation-2_interpretability.ipynb`
     - `evaluation-3_runtime.ipynb`
     - `evaluation-4_reversed.ipynb`
   - These analyze performance metrics, interpretability, runtime comparisons, and a reversed hierarchy.

2. **Figures and Logs**  
   - Plots generated by these notebooks are stored in `Evaluation/figures/`.
   - PyTorch Lightning logs appear in subfolders named `lightning_logs`.

3. **Trained Model Checkpoints**  
   - Existing model checkpoints for HNAM (and other baselines) are in `Fit_and_Predict/models/...`.
   - `predict_all.py` uses these checkpoints to produce forecasts without retraining.

---

## Citing this Work

Available after review process.

---

## Contact & Support

Available after review process.

---

Happy forecasting!
