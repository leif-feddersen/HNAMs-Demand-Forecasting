# HNAM Experiments

This repository contains the experimental code, data structure, and pre-trained model checkpoints used in the paper:

> **Hierarchical Neural Additive Models for Interpretable Demand Forecasts**  
> Under Review

---

## Overview

1. **Purpose**  
   - Demonstrates the use of **Hierarchical Neural Additive Models (HNAMs)** for interpretable demand forecasting on two real-world datasets:
     - [Favorita Grocery Sales Forecasting (Kaggle)](https://www.kaggle.com/competitions/favorita-grocery-sales-forecasting/)
     - [Walmart M5 Forecasting (Kaggle)](https://www.kaggle.com/competitions/m5-forecasting-accuracy/)
   - Includes scripts for data preprocessing, evaluation notebooks for accuracy/interpretability/runtime, and pre-trained HNAM checkpoints.

2. **Repository Structure**  
   - **`Datasets/`**  
     - Place original CSVs from the Kaggle competitions inside `Datasets/Favorita` and `Datasets/Walmart`.  
   - **`Preprocessing/`**  
     - Python scripts for data cleaning, transformation, and serialization.
   - **`Fit_and_Predict/`**  
     - Scripts for training various models (HNAM, TFT, ARIMA, Prophet, etc.).  
     - Includes subfolders with model checkpoints.  
   - **`Evaluation/`**  
     - Jupyter notebooks (`evaluation-*.ipynb`) for analyzing results (accuracy, interpretability, runtime).  
     - `predict_all.py` script to generate forecasts from pre-trained models for complete datasets. 
     - Figures, logs, and saved predictions (`.pkl`) are also stored here.  
   - **`Processed/`**  
     - Intermediate `.pkl` data files from the preprocessing stage.  
   - **`run.sh`**  
     - A single script that preprocesses the data and then uses pre-trained HNAM models to produce forecasts across all datasets.

3. **Conda Environment**  
   - **`env.yml`** describes the environment needed to run all experiments (creates an environment named `hnam`).  
   - This includes the [custom PyTorch Forecasting fork](https://github.com/leif-feddersen/pytorch-forecasting/tree/hnam-mods) with HNAM support.

---

## Getting Started

### 1. Clone the Repository

~~~bash
git clone https://github.com/leif-feddersen/hnam_experiments.git
cd hnam_experiments
~~~

### 2. Create and Activate the Conda Environment

Make sure you have [Conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/) installed. Then:

~~~bash
conda env create -f env.yml
conda activate hnam
~~~

--- 

<br><b>If you wish to do local inference in the complete datasets, continue with 3 and 4.</b><br>
### 3. Place the Data

Obtain the original CSVs from Kaggle for both **Favorita** and **Walmart** competitions. Place them in:

```
hnam_experiments/
└── Datasets/
    ├── Favorita/
    │   ├── holidays_events.csv
    │   ├── items.csv
    │   ├── oil.csv
    │   ├── sample_submission.csv
    │   ├── stores.csv
    │   ├── test.csv
    │   ├── train.csv
    │   └── transactions.csv
    └── Walmart/
        ├── calendar.csv
        ├── sales_train_evaluation.csv
        ├── sales_train_validation.csv
        ├── sample_submission.csv
        └── sell_prices.csv
```


### 4. 

Execute script `run.sh` from the repository’s root directory:

~~~bash
bash run.sh
~~~

What this does:

1. **Preprocessing**  
   - Enters `Preprocessing/`.
   - Runs `python pre_walmart.py` and `python pre_favorita.py` to generate processed `.pkl` files under `Processed/`.

2. **Prediction**  
   - Moves into `Evaluation/`.
   - Calls `predict_all.py` for each dataset (`Walmart`, `WalmartR`, and `Favorita`) to use the pre-trained HNAM models and produce full forecasts.

---

## Results and Evaluation

1. **Evaluation Notebooks**  
   - In `Evaluation/`, you’ll find Jupyter notebooks such as:
     - `evaluation-1_accuracy.ipynb`
     - `evaluation-2_interpretability.ipynb`
     - `evaluation-3_runtime.ipynb`
     - `evaluation-4_reversed.ipynb`
   - These analyze performance metrics, interpretability, and runtime comparisons.

2. **Figures and Logs**  
   - Plots generated by these notebooks are stored in `Evaluation/figures/`.
   - PyTorch Lightning logs appear in subfolders named `lightning_logs`.

3. **Trained Model Checkpoints**  
   - Existing model checkpoints for HNAM (and other baselines) are in `Fit_and_Predict/models/...`.
   - `predict_all.py` uses these checkpoints to produce forecasts without retraining.

---

## Citing this Work

Available after review process.

---

## Contact & Support

Available after review process.

---

Happy forecasting!
